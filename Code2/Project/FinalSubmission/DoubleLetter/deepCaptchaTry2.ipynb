{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "067c33e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import get_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2fda7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "489cf6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = './../Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8909e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptchaDataset(Dataset):\n",
    "    def __init__(self, root_dir, annotation_file, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.annotations = pd.read_csv(f\"{root_dir}{annotation_file}\", dtype=str)\n",
    "        self.annotations = self.annotations[self.annotations['length']=='3']\n",
    "        self.annotations = self.annotations\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_id = self.annotations.iloc[index]\n",
    "        img = Image.open(\n",
    "            # os.path.join( self.root_dir, 'NewDataset', 'data', img_id['category'], f\"Len{img_id['length']}Char\", img_id['file'])\n",
    "            os.path.join( self.root_dir, 'NewDataset', f\"Len{img_id['length']}Char\", 'data', img_id['file'])\n",
    "          ).convert(\"L\")\n",
    "        # print(img_id['length'], len(str(img_id['text'])))\n",
    "        y_label = (int(img_id['length']), img_id['text']) #int(img_id['text'][1]), int(img_id['text'][2]), int(img_id['text'][3]), int(img_id['text'][4]))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return (img, y_label)\n",
    "# class CaptchaDataset(Dataset):\n",
    "#     def __init__(self, root_dir, annotation_file, transform=None):\n",
    "#         self.root_dir = root_dir\n",
    "#         self.annotations = pd.read_csv(f\"./{annotation_file}\", dtype=str)\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.annotations)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         img_id = self.annotations.iloc[index]\n",
    "#         img = Image.open(\n",
    "#             # os.path.join( self.root_dir, img_id['category'], f\"Len{img_id['length']}Char\", img_id['file'])\n",
    "#             os.path.join( self.root_dir, img_id['file'])\n",
    "#           ).convert(\"L\")\n",
    "#         # print('qwerty  ', img_id['text'])\n",
    "#         y_label = (img_id['length'], str(img_id['text']))\n",
    "\n",
    "#         if self.transform is not None:\n",
    "#             img = self.transform(img)\n",
    "  \n",
    "#         return (img, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "247ed62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((60, 200)),\n",
    "        # transforms.RandomCrop((299, 299)),\n",
    "        # transforms.Resize((256,256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, ), (0.5, )),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b451d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6acda67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "dataset = CaptchaDataset(BASE_DIR, \"Num.csv\", transform = transform)\n",
    "print(len(dataset))\n",
    "train_set, validation_set, test_set = torch.utils.data.random_split(dataset, [4000, 500, 500])\n",
    "# train_set, validation_set = torch.utils.data.random_split(dataset, [8000,2001])\n",
    "\n",
    "train_loader = DataLoader(dataset = train_set, shuffle = True, batch_size = BATCH)\n",
    "validation_loader = DataLoader(dataset = validation_set, shuffle = True, batch_size = BATCH)\n",
    "test_loader = DataLoader(dataset = test_set, shuffle = True, batch_size = BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55f54201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 1, 60, 200])\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(type(labels[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "047a90d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT_PROB = 0.3\n",
    "# N_EPOCHS = 10\n",
    "# model_path = './Models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c06fbbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dropout_flag=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.dropout_flag = dropout_flag  # 1->Conv Layer, 2->FC Layer\n",
    "\n",
    "        self.blockA = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding='same'),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.blockA_drop = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(DROPOUT_PROB),\n",
    "        )\n",
    "\n",
    "        self.blockB = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=48, kernel_size=5, stride=1, padding='same'),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.blockB_drop = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=48, kernel_size=5, stride=1, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(DROPOUT_PROB),\n",
    "        )\n",
    "\n",
    "        self.blockC = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=48, out_channels=64, kernel_size=5, stride=1, padding='same'),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.blockC_drop = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=48, out_channels=64, kernel_size=5, stride=1, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(DROPOUT_PROB),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(5*2240, 512)\n",
    "        self.out1 = nn.Linear(512, 11)\n",
    "        self.out2 = nn.Linear(512, 11)\n",
    "        self.out3 = nn.Linear(512, 11)\n",
    "        self.out4 = nn.Linear(512, 11)\n",
    "        self.out5 = nn.Linear(512, 11)\n",
    "\n",
    "        self.length_out = nn.Linear(512, 5)\n",
    "\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # self.drop = nn.Dropout(DROPOUT_PROB)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.blockA(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.blockB(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.blockC_drop(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        x = self.relu(self.fc1(x))\n",
    "\n",
    "        label1 = self.out1(x)\n",
    "        label2 = self.out2(x)\n",
    "        label3 = self.out3(x)\n",
    "        label4 = self.out4(x)\n",
    "        label5 = self.out5(x)\n",
    "\n",
    "        length = self.softmax(self.length_out(x))\n",
    "\n",
    "        # return {'label1':label1, 'label2':label2, 'label3':label3, 'label4':label4, 'label5':label5}\n",
    "\n",
    "        return {'label': torch.stack([label1, label2, label3, label4, label5], dim=1), 'length': length}\n",
    "        # return {'label': torch.stack([label1, label2], dim=1), 'length': length}\n",
    "        # return {'label': label1, 'length': length}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3998550",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1071ae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f23700b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the default learning rate scheduler\n",
    "num_epochs = 50\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", \n",
    "    optimizer=optimizer, \n",
    "    num_warmup_steps=0, \n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8bd5e280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb6c7a8b33a45018b90299a4353473e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mann/.local/lib/python3.6/site-packages/ipykernel_launcher.py:79: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]  Training Loss: 0.54668  Acc1: 9.85000  Acc2: 10.00000  Acc3: 9.27500  Acc4: 99.85001  Acc5: 99.20000 \n",
      "Epoch 0,  Loss : 0.5466845873594284,  Acc : 0.00025\n",
      "Epoch [2/50]  Training Loss: 0.44922  Acc1: 9.25000  Acc2: 9.60000  Acc3: 10.12500  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 1,  Loss : 0.4492244999408722,  Acc : 0.00025\n",
      "Epoch [3/50]  Training Loss: 0.50926  Acc1: 9.25000  Acc2: 10.10000  Acc3: 9.45000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 2,  Loss : 0.5092618631124497,  Acc : 0.00075\n",
      "Epoch [4/50]  Training Loss: 0.48454  Acc1: 10.02500  Acc2: 9.45000  Acc3: 10.25000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 3,  Loss : 0.4845437585115433,  Acc : 0.00125\n",
      "Epoch [5/50]  Training Loss: 0.44076  Acc1: 9.85000  Acc2: 9.72500  Acc3: 9.72500  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 4,  Loss : 0.4407629736661911,  Acc : 0.0\n",
      "Epoch [6/50]  Training Loss: 0.43417  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 5,  Loss : 0.4341730234622955,  Acc : 0.0\n",
      "Epoch [7/50]  Training Loss: 0.46533  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 6,  Loss : 0.46533322870731353,  Acc : 0.0\n",
      "Epoch [8/50]  Training Loss: 0.53005  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 7,  Loss : 0.5300510052442551,  Acc : 0.0\n",
      "Epoch [9/50]  Training Loss: 0.47578  Acc1: 10.25000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 8,  Loss : 0.47578450858592986,  Acc : 0.0\n",
      "Epoch [10/50]  Training Loss: 0.46036  Acc1: 9.67500  Acc2: 9.72500  Acc3: 10.15000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 9,  Loss : 0.46035570311546326,  Acc : 0.00125\n",
      "Epoch [11/50]  Training Loss: 0.46302  Acc1: 9.55000  Acc2: 10.02500  Acc3: 10.57500  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 10,  Loss : 0.4630203821659088,  Acc : 0.00025\n",
      "Epoch [12/50]  Training Loss: 0.44957  Acc1: 9.75000  Acc2: 9.95000  Acc3: 10.25000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 11,  Loss : 0.4495668358802795,  Acc : 0.001\n",
      "Epoch [13/50]  Training Loss: 0.44189  Acc1: 9.75000  Acc2: 9.95000  Acc3: 10.25000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 12,  Loss : 0.4418896474838257,  Acc : 0.001\n",
      "Epoch [14/50]  Training Loss: 0.43745  Acc1: 9.75000  Acc2: 9.95000  Acc3: 9.92500  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 13,  Loss : 0.43745174527168273,  Acc : 0.00025\n",
      "Epoch [15/50]  Training Loss: 0.43479  Acc1: 9.70000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 14,  Loss : 0.4347942316532135,  Acc : 0.0\n",
      "Epoch [16/50]  Training Loss: 0.43126  Acc1: 10.05000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 15,  Loss : 0.4312555434703827,  Acc : 0.0\n",
      "Epoch [17/50]  Training Loss: 0.42786  Acc1: 9.60000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 16,  Loss : 0.42785614013671874,  Acc : 0.0\n",
      "Epoch [18/50]  Training Loss: 0.42686  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 17,  Loss : 0.42686147439479827,  Acc : 0.0\n",
      "Epoch [19/50]  Training Loss: 0.42785  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 18,  Loss : 0.42785330975055696,  Acc : 0.0\n",
      "Epoch [20/50]  Training Loss: 0.42851  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 19,  Loss : 0.42850625133514403,  Acc : 0.0\n",
      "Epoch [21/50]  Training Loss: 0.42830  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 20,  Loss : 0.4282971167564392,  Acc : 0.0\n",
      "Epoch [22/50]  Training Loss: 0.42752  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 21,  Loss : 0.4275211036205292,  Acc : 0.0\n",
      "Epoch [23/50]  Training Loss: 0.42658  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 22,  Loss : 0.4265838100910187,  Acc : 0.0\n",
      "Epoch [24/50]  Training Loss: 0.42651  Acc1: 9.32500  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 23,  Loss : 0.42650750505924223,  Acc : 0.0\n",
      "Epoch [25/50]  Training Loss: 0.42706  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 24,  Loss : 0.42705608761310576,  Acc : 0.0\n",
      "Epoch [26/50]  Training Loss: 0.42726  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 25,  Loss : 0.42726486909389494,  Acc : 0.0\n",
      "Epoch [27/50]  Training Loss: 0.42673  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 26,  Loss : 0.4267267290353775,  Acc : 0.0\n",
      "Epoch [28/50]  Training Loss: 0.42643  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 27,  Loss : 0.4264325385093689,  Acc : 0.0\n",
      "Epoch [29/50]  Training Loss: 0.42617  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 28,  Loss : 0.42617157971858977,  Acc : 0.0\n",
      "Epoch [30/50]  Training Loss: 0.42640  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 29,  Loss : 0.42640471971035004,  Acc : 0.0\n",
      "Epoch [31/50]  Training Loss: 0.42654  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 30,  Loss : 0.4265384767055512,  Acc : 0.0\n",
      "Epoch [32/50]  Training Loss: 0.42620  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 31,  Loss : 0.42619985926151277,  Acc : 0.0\n",
      "Epoch [33/50]  Training Loss: 0.42603  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 32,  Loss : 0.42602541828155516,  Acc : 0.0\n",
      "Epoch [34/50]  Training Loss: 0.42596  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 33,  Loss : 0.42595841789245603,  Acc : 0.0\n",
      "Epoch [35/50]  Training Loss: 0.42615  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 34,  Loss : 0.4261485654115677,  Acc : 0.0\n",
      "Epoch [36/50]  Training Loss: 0.42608  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 35,  Loss : 0.42608161556720736,  Acc : 0.0\n",
      "Epoch [37/50]  Training Loss: 0.42579  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 36,  Loss : 0.4257946721315384,  Acc : 0.0\n",
      "Epoch [38/50]  Training Loss: 0.42580  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 37,  Loss : 0.42580123388767244,  Acc : 0.0\n",
      "Epoch [39/50]  Training Loss: 0.42586  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 38,  Loss : 0.42585917782783506,  Acc : 0.0\n",
      "Epoch [40/50]  Training Loss: 0.42584  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 39,  Loss : 0.42584213733673093,  Acc : 0.0\n",
      "Epoch [41/50]  Training Loss: 0.42580  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 40,  Loss : 0.4258025480508804,  Acc : 0.0\n",
      "Epoch [42/50]  Training Loss: 0.42575  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 41,  Loss : 0.4257493472099304,  Acc : 0.0\n",
      "Epoch [43/50]  Training Loss: 0.42571  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 42,  Loss : 0.4257067781686783,  Acc : 0.0\n",
      "Epoch [44/50]  Training Loss: 0.42572  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 43,  Loss : 0.4257213236093521,  Acc : 0.0\n",
      "Epoch [45/50]  Training Loss: 0.42574  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 44,  Loss : 0.42573541796207426,  Acc : 0.0\n",
      "Epoch [46/50]  Training Loss: 0.42568  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 45,  Loss : 0.42567542278766635,  Acc : 0.0\n",
      "Epoch [47/50]  Training Loss: 0.42564  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 46,  Loss : 0.42563851618766785,  Acc : 0.0\n",
      "Epoch [48/50]  Training Loss: 0.42563  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 47,  Loss : 0.42562915229797366,  Acc : 0.0\n",
      "Epoch [49/50]  Training Loss: 0.42563  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 48,  Loss : 0.4256287097930908,  Acc : 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50]  Training Loss: 0.42562  Acc1: 9.35000  Acc2: 9.95000  Acc3: 9.90000  Acc4: 100.00000  Acc5: 100.00000 \n",
      "Epoch 49,  Loss : 0.4256163376569748,  Acc : 0.0\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "# def train(model, title, regularization = None):\n",
    "    \n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "trainlosslist = []\n",
    "validationlosslist = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    train_correct1 = 0\n",
    "    train_correct2 = 0\n",
    "    train_correct3 = 0\n",
    "    train_correct4 = 0\n",
    "    train_correct5 = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    validation_loss = 0.0\n",
    "    validation_correct = 0\n",
    "    validation_total = 0\n",
    "\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs = data[0].to(device)\n",
    "        labels = data[1]\n",
    "        \n",
    "        label = []\n",
    "        \n",
    "        for l in range(len(labels[0])):\n",
    "            label.append([])\n",
    "            length = labels[0][l]\n",
    "\n",
    "            for j in range(int(length)):\n",
    "                character = labels[1][l][j]\n",
    "                output_array = [0]*11\n",
    "                output_array[int(character)] = 1\n",
    "                label[l].append(output_array)\n",
    "\n",
    "            for j in range(int(length), 5):\n",
    "                output_array = [0]*11\n",
    "                output_array[10] = 1\n",
    "                label[l].append(output_array)\n",
    "\n",
    "        label = torch.Tensor(label).to(device)\n",
    "        outputs = model(inputs.to(device))\n",
    "        # print(label.shape)\n",
    "        # print(outputs['label'].shape)\n",
    "        # calculate loss\n",
    "        loss_label = criterion(outputs['label'], label)\n",
    "\n",
    "        # loss = loss #+ loss2 + loss3 + loss4 + loss5\n",
    "        loss = loss_label\n",
    "\n",
    "        pred = torch.argmax(outputs['label'], 2)\n",
    "        \n",
    "        label = torch.argmax(label, axis=2)\n",
    "\n",
    "        train_correct += (torch.sum(label==pred, axis=1)==5).nonzero().shape[0]\n",
    "        \n",
    "        train_total += BATCH\n",
    "        \n",
    "        correct = torch.sum(label==pred, axis=0)\n",
    "\n",
    "        train_correct1 += (correct[0])\n",
    "        train_correct2 += (correct[1])\n",
    "        train_correct3 += (correct[2])\n",
    "        train_correct4 += (correct[3])\n",
    "        train_correct5 += (correct[4])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        progress_bar.update(1)\n",
    "        # print statistics\n",
    "        train_loss += loss.item()\n",
    "\n",
    "\n",
    "    epoch_train_loss = train_loss/len(train_loader)\n",
    "    # epoch_validation_loss = validation_loss/len(validation_loader) \n",
    "    epoch_train_acc1 = (train_correct1/train_total)*100\n",
    "    epoch_train_acc2 = (train_correct2/train_total)*100\n",
    "    epoch_train_acc3 = (train_correct3/train_total)*100\n",
    "    epoch_train_acc4 = (train_correct4/train_total)*100\n",
    "    epoch_train_acc5 = (train_correct5/train_total)*100\n",
    "    # epoch_validation_acc = (validation_correct1/validation_total)*100\n",
    "\n",
    "    print(\"Epoch [%d/%d]  Training Loss: %.5f  Acc1: %.5f  Acc2: %.5f  Acc3: %.5f  Acc4: %.5f  Acc5: %.5f \" %(epoch+1, num_epochs, epoch_train_loss, epoch_train_acc1, epoch_train_acc2, epoch_train_acc3, epoch_train_acc4, epoch_train_acc5))\n",
    "    print(f\"Epoch {epoch},  Loss : {epoch_train_loss},  Acc : {train_correct/train_total}\")\n",
    "    \n",
    "    # print(\"Epoch [%d/%d]  Training Loss: %.5f  Training Acc: %.5f  Validation Loss: %.5f   Validation Accuracy: %.5f \" %(epoch+1, N_EPOCHS, epoch_train_loss, epoch_train_acc, epoch_validation_loss, epoch_validation_acc))\n",
    "    trainlosslist.append(epoch_train_loss)\n",
    "    \n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# plot(trainlosslist, validationlosslist, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a40278b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfcdbdc31e464fb6bd76ec213a9248cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mann/.local/lib/python3.6/site-packages/ipykernel_launcher.py:79: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50]  Validation Loss: 0.42562  Acc1: 9.17553  Acc2: 10.28369  Acc3: 9.97340  Acc4: 99.73404  Acc5: 99.73404 \n",
      "Epoch 49,  Loss : 0.4256163376569748,  Acc : 0.0\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for i, data in tqdm(enumerate(validation_loader)):\n",
    "    inputs = data[0].to(device)\n",
    "    labels = data[1]\n",
    "    \n",
    "    label = []\n",
    "    \n",
    "    for l in range(len(labels[0])):\n",
    "        label.append([])\n",
    "        length = labels[0][l]\n",
    "\n",
    "        for j in range(int(length)):\n",
    "            character = labels[1][l][j]\n",
    "            output_array = [0]*11\n",
    "            output_array[int(character)] = 1\n",
    "            label[l].append(output_array)\n",
    "\n",
    "        for j in range(int(length), 5):\n",
    "            output_array = [0]*11\n",
    "            output_array[10] = 1\n",
    "            label[l].append(output_array)\n",
    "\n",
    "    label = torch.Tensor(label).to(device)\n",
    "    outputs = model(inputs.to(device))\n",
    "\n",
    "    # # calculate loss\n",
    "    # loss_label = criterion(outputs['label'], label)\n",
    "\n",
    "    # # loss = loss #+ loss2 + loss3 + loss4 + loss5\n",
    "    # loss = loss_label\n",
    "\n",
    "    pred = torch.argmax(outputs['label'], 2)\n",
    "    \n",
    "    label = torch.argmax(label, axis=2)\n",
    "\n",
    "    train_correct += (torch.sum(label==pred, axis=1)==5).nonzero().shape[0]\n",
    "    \n",
    "    train_total += BATCH\n",
    "    \n",
    "    correct = torch.sum(label==pred, axis=0)\n",
    "    \n",
    "    train_correct1 += (correct[0])\n",
    "    train_correct2 += (correct[1])\n",
    "    train_correct3 += (correct[2])\n",
    "    train_correct4 += (correct[3])\n",
    "    train_correct5 += (correct[4])\n",
    "\n",
    "epoch_train_loss = train_loss/len(train_loader)\n",
    "# epoch_validation_loss = validation_loss/len(validation_loader) \n",
    "epoch_train_acc1 = (train_correct1/train_total)*100\n",
    "epoch_train_acc2 = (train_correct2/train_total)*100\n",
    "epoch_train_acc3 = (train_correct3/train_total)*100\n",
    "epoch_train_acc4 = (train_correct4/train_total)*100\n",
    "epoch_train_acc5 = (train_correct5/train_total)*100\n",
    "# epoch_validation_acc = (validation_correct1/validation_total)*100\n",
    "\n",
    "print(\"Epoch [%d/%d]  Validation Loss: %.5f  Acc1: %.5f  Acc2: %.5f  Acc3: %.5f  Acc4: %.5f  Acc5: %.5f \" %(epoch+1, num_epochs, epoch_train_loss, epoch_train_acc1, epoch_train_acc2, epoch_train_acc3, epoch_train_acc4, epoch_train_acc5))\n",
    "print(f\"Epoch {epoch},  Loss : {epoch_train_loss},  Acc : {train_correct/train_total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95790496",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './varLengthChar3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b2fc71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
