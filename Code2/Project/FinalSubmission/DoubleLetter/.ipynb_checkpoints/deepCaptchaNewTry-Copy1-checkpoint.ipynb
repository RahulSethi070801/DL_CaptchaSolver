{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7425fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import get_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d72178d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db811fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = './../Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaf051cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptchaDataset(Dataset):\n",
    "    def __init__(self, root_dir, annotation_file, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.annotations = pd.read_csv(f\"{root_dir}{annotation_file}\", dtype=str)\n",
    "        # self.annotations = self.annotations[self.annotations['length']=='5']\n",
    "        self.annotations = self.annotations\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_id = self.annotations.iloc[index]\n",
    "        img = Image.open(\n",
    "            # os.path.join( self.root_dir, 'NewDataset', 'data', img_id['category'], f\"Len{img_id['length']}Char\", img_id['file'])\n",
    "            os.path.join( self.root_dir, 'NewDataset', f\"Len{img_id['length']}Char\", 'data', img_id['file'])\n",
    "          ).convert(\"L\")\n",
    "        # print(img_id['length'], len(str(img_id['text'])))\n",
    "        y_label = (int(img_id['length']), img_id['text']) #int(img_id['text'][1]), int(img_id['text'][2]), int(img_id['text'][3]), int(img_id['text'][4]))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return (img, y_label)\n",
    "# class CaptchaDataset(Dataset):\n",
    "#     def __init__(self, root_dir, annotation_file, transform=None):\n",
    "#         self.root_dir = root_dir\n",
    "#         self.annotations = pd.read_csv(f\"./{annotation_file}\", dtype=str)\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.annotations)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         img_id = self.annotations.iloc[index]\n",
    "#         img = Image.open(\n",
    "#             # os.path.join( self.root_dir, img_id['category'], f\"Len{img_id['length']}Char\", img_id['file'])\n",
    "#             os.path.join( self.root_dir, img_id['file'])\n",
    "#           ).convert(\"L\")\n",
    "#         # print('qwerty  ', img_id['text'])\n",
    "#         y_label = (img_id['length'], str(img_id['text']))\n",
    "\n",
    "#         if self.transform is not None:\n",
    "#             img = self.transform(img)\n",
    "  \n",
    "#         return (img, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33f8e8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((60, 200)),\n",
    "        # transforms.RandomCrop((299, 299)),\n",
    "        # transforms.Resize((256,256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, ), (0.5, )),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b3c7291",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdaf33c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "dataset = CaptchaDataset(BASE_DIR, \"Num.csv\", transform = transform)\n",
    "print(len(dataset))\n",
    "train_set, validation_set, test_set = torch.utils.data.random_split(dataset, [21000, 2000, 2000])\n",
    "# train_set, validation_set = torch.utils.data.random_split(dataset, [8000,2001])\n",
    "\n",
    "train_loader = DataLoader(dataset = train_set, shuffle = True, batch_size = BATCH)\n",
    "validation_loader = DataLoader(dataset = validation_set, shuffle = True, batch_size = BATCH)\n",
    "test_loader = DataLoader(dataset = test_set, shuffle = True, batch_size = BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68918904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 1, 60, 200])\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(type(labels[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8ce72b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT_PROB = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "398030cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dropout_flag=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.dropout_flag = dropout_flag  # 1->Conv Layer, 2->FC Layer\n",
    "\n",
    "        self.blockA = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding='same'),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.blockA_drop = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(DROPOUT_PROB),\n",
    "        )\n",
    "\n",
    "        self.blockB = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=48, kernel_size=5, stride=1, padding='same'),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.blockB_drop = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=48, kernel_size=5, stride=1, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(DROPOUT_PROB),\n",
    "        )\n",
    "\n",
    "        self.blockC = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=48, out_channels=64, kernel_size=5, stride=1, padding='same'),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.blockC_drop = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=48, out_channels=64, kernel_size=5, stride=1, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(DROPOUT_PROB),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(11200, 512)\n",
    "        self.out1 = nn.Linear(512, 11)\n",
    "        self.out2 = nn.Linear(512, 11)\n",
    "        self.out3 = nn.Linear(512, 11)\n",
    "        self.out4 = nn.Linear(512, 11)\n",
    "        self.out5 = nn.Linear(512, 11)\n",
    "\n",
    "        self.length_out = nn.Linear(512, 5)\n",
    "\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # self.drop = nn.Dropout(DROPOUT_PROB)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.blockA(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.blockB(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.blockC_drop(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        x = self.relu(self.fc1(x))\n",
    "\n",
    "        label1 = self.out1(x)\n",
    "        label2 = self.out2(x)\n",
    "        label3 = self.out3(x)\n",
    "        label4 = self.out4(x)\n",
    "        label5 = self.out5(x)\n",
    "\n",
    "        length = self.length_out(x)\n",
    "\n",
    "        # return {'label1':label1, 'label2':label2, 'label3':label3, 'label4':label4, 'label5':label5}\n",
    "\n",
    "        return {'label': torch.stack([label1, label2, label3, label4, label5], dim=1), 'length': length}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6ca45a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9052787",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43f63243",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the default learning rate scheduler\n",
    "num_epochs = 50\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", \n",
    "    optimizer=optimizer, \n",
    "    num_warmup_steps=0, \n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7489f935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e807bde3959e42a39f24e4221201c3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]  Training Loss: 0.64657  Acc1: 19.47354  Acc2: 8.15404  Acc3: 23.79094  Acc4: 58.14928  Acc5: 79.66965 \n",
      "Epoch 0,  Loss : 0.6465676249844012,  Acc : 0.0003808073115003808\n",
      "Epoch [2/50]  Training Loss: 0.64068  Acc1: 20.01143  Acc2: 8.46344  Acc3: 36.64795  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 1,  Loss : 0.6406806531246618,  Acc : 0.0008568164508758568\n",
      "Epoch [3/50]  Training Loss: 0.63789  Acc1: 20.01143  Acc2: 8.63005  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 2,  Loss : 0.6378905370956328,  Acc : 0.001904036557501904\n",
      "Epoch [4/50]  Training Loss: 0.63562  Acc1: 20.01143  Acc2: 8.32540  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 3,  Loss : 0.63562214892054,  Acc : 0.0012376237623762376\n",
      "Epoch [5/50]  Training Loss: 0.63480  Acc1: 20.01143  Acc2: 8.74905  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 4,  Loss : 0.6348020740801019,  Acc : 0.0024752475247524753\n",
      "Epoch [6/50]  Training Loss: 0.63451  Acc1: 20.01143  Acc2: 14.68488  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 5,  Loss : 0.6345131413589792,  Acc : 0.012376237623762377\n",
      "Epoch [7/50]  Training Loss: 0.63381  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 6,  Loss : 0.633812279303566,  Acc : 0.019897182025894897\n",
      "Epoch [8/50]  Training Loss: 0.63355  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 7,  Loss : 0.6335541874692354,  Acc : 0.019897182025894897\n",
      "Epoch [9/50]  Training Loss: 0.63362  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 8,  Loss : 0.6336180171890288,  Acc : 0.019897182025894897\n",
      "Epoch [10/50]  Training Loss: 0.63340  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 9,  Loss : 0.6334000483143901,  Acc : 0.019897182025894897\n",
      "Epoch [11/50]  Training Loss: 0.63455  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 10,  Loss : 0.634550202964193,  Acc : 0.019897182025894897\n",
      "Epoch [12/50]  Training Loss: 0.63449  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 11,  Loss : 0.6344906955117591,  Acc : 0.019897182025894897\n",
      "Epoch [13/50]  Training Loss: 0.63471  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 12,  Loss : 0.6347125797714791,  Acc : 0.019897182025894897\n",
      "Epoch [14/50]  Training Loss: 0.63481  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 13,  Loss : 0.6348144903222932,  Acc : 0.019897182025894897\n",
      "Epoch [15/50]  Training Loss: 0.63489  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 14,  Loss : 0.6348859093975494,  Acc : 0.019897182025894897\n",
      "Epoch [16/50]  Training Loss: 0.63437  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 15,  Loss : 0.634365668799799,  Acc : 0.019897182025894897\n",
      "Epoch [17/50]  Training Loss: 0.63360  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 16,  Loss : 0.6335979534847902,  Acc : 0.019897182025894897\n",
      "Epoch [18/50]  Training Loss: 0.63334  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 17,  Loss : 0.6333353118141098,  Acc : 0.019897182025894897\n",
      "Epoch [19/50]  Training Loss: 0.63346  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 18,  Loss : 0.6334596180952149,  Acc : 0.019897182025894897\n",
      "Epoch [20/50]  Training Loss: 0.63343  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 19,  Loss : 0.6334340435715913,  Acc : 0.019897182025894897\n",
      "Epoch [21/50]  Training Loss: 0.63363  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 20,  Loss : 0.6336310840433822,  Acc : 0.019897182025894897\n",
      "Epoch [22/50]  Training Loss: 0.63389  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 21,  Loss : 0.6338923726477699,  Acc : 0.019897182025894897\n",
      "Epoch [23/50]  Training Loss: 0.63360  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 22,  Loss : 0.6336014277137878,  Acc : 0.019897182025894897\n",
      "Epoch [24/50]  Training Loss: 0.63330  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 23,  Loss : 0.6332999126473549,  Acc : 0.019897182025894897\n",
      "Epoch [25/50]  Training Loss: 0.63346  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 24,  Loss : 0.6334590903693996,  Acc : 0.019897182025894897\n",
      "Epoch [26/50]  Training Loss: 0.63325  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 25,  Loss : 0.6332524368441568,  Acc : 0.019897182025894897\n",
      "Epoch [27/50]  Training Loss: 0.63314  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 26,  Loss : 0.6331405754045776,  Acc : 0.019897182025894897\n",
      "Epoch [28/50]  Training Loss: 0.63319  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 27,  Loss : 0.6331876899936412,  Acc : 0.019897182025894897\n",
      "Epoch [29/50]  Training Loss: 0.63322  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 28,  Loss : 0.6332176024915603,  Acc : 0.019897182025894897\n",
      "Epoch [30/50]  Training Loss: 0.63321  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 29,  Loss : 0.6332087989354623,  Acc : 0.019897182025894897\n",
      "Epoch [31/50]  Training Loss: 0.63289  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 30,  Loss : 0.6328924422216887,  Acc : 0.019897182025894897\n",
      "Epoch [32/50]  Training Loss: 0.63305  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 31,  Loss : 0.6330477253045186,  Acc : 0.019897182025894897\n",
      "Epoch [33/50]  Training Loss: 0.63295  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 32,  Loss : 0.6329478906568279,  Acc : 0.019897182025894897\n",
      "Epoch [34/50]  Training Loss: 0.63290  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 33,  Loss : 0.6329048650462665,  Acc : 0.019897182025894897\n",
      "Epoch [35/50]  Training Loss: 0.63301  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 34,  Loss : 0.6330090922339673,  Acc : 0.019897182025894897\n",
      "Epoch [36/50]  Training Loss: 0.63299  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 35,  Loss : 0.6329863671573718,  Acc : 0.019897182025894897\n",
      "Epoch [37/50]  Training Loss: 0.63273  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 36,  Loss : 0.6327319564659543,  Acc : 0.019897182025894897\n",
      "Epoch [38/50]  Training Loss: 0.63258  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 37,  Loss : 0.6325835701807346,  Acc : 0.019897182025894897\n",
      "Epoch [39/50]  Training Loss: 0.63262  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 38,  Loss : 0.6326169489179961,  Acc : 0.019897182025894897\n",
      "Epoch [40/50]  Training Loss: 0.63271  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 39,  Loss : 0.6327120358945755,  Acc : 0.019897182025894897\n",
      "Epoch [41/50]  Training Loss: 0.63268  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 40,  Loss : 0.6326787867168389,  Acc : 0.019897182025894897\n",
      "Epoch [42/50]  Training Loss: 0.63264  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 41,  Loss : 0.6326368916879059,  Acc : 0.019897182025894897\n",
      "Epoch [43/50]  Training Loss: 0.63260  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 42,  Loss : 0.6325966237795235,  Acc : 0.019897182025894897\n",
      "Epoch [44/50]  Training Loss: 0.63258  Acc1: 20.01143  Acc2: 20.03522  Acc3: 39.82293  Acc4: 59.92955  Acc5: 79.79817 \n",
      "Epoch 43,  Loss : 0.6325793783354197,  Acc : 0.019897182025894897\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "# def train(model, title, regularization = None):\n",
    "    \n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "trainlosslist = []\n",
    "validationlosslist = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    train_correct1 = 0\n",
    "    train_correct2 = 0\n",
    "    train_correct3 = 0\n",
    "    train_correct4 = 0\n",
    "    train_correct5 = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    validation_loss = 0.0\n",
    "    validation_correct = 0\n",
    "    validation_total = 0\n",
    "\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs = data[0].to(device)\n",
    "        labels = data[1]\n",
    "        \n",
    "        label = []\n",
    "        \n",
    "        for l in range(len(labels[0])):\n",
    "            label.append([])\n",
    "            length = labels[0][l]\n",
    "\n",
    "            for j in range(int(length)):\n",
    "                character = labels[1][l][j]\n",
    "                output_array = [0]*11\n",
    "                output_array[int(character)] = 1\n",
    "                label[l].append(output_array)\n",
    "\n",
    "            for j in range(int(length), 5):\n",
    "                output_array = [0]*11\n",
    "                output_array[10] = 1\n",
    "                label[l].append(output_array)\n",
    "\n",
    "        label = torch.Tensor(label).to(device)\n",
    "        outputs = model(inputs.to(device))\n",
    "\n",
    "        # calculate loss\n",
    "        loss_label = criterion(outputs['label'], label)\n",
    "\n",
    "        # loss = loss #+ loss2 + loss3 + loss4 + loss5\n",
    "        loss = loss_label\n",
    "\n",
    "        pred = torch.argmax(outputs['label'], 2)\n",
    "        \n",
    "        label = torch.argmax(label, axis=2)\n",
    "\n",
    "        train_correct += (torch.sum(label==pred, axis=1)==5).nonzero().shape[0]\n",
    "        \n",
    "        train_total += BATCH\n",
    "        \n",
    "        correct = torch.sum(label==pred, axis=0)\n",
    "\n",
    "        train_correct1 += (correct[0])\n",
    "        train_correct2 += (correct[1])\n",
    "        train_correct3 += (correct[2])\n",
    "        train_correct4 += (correct[3])\n",
    "        train_correct5 += (correct[4])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        progress_bar.update(1)\n",
    "        # print statistics\n",
    "        train_loss += loss.item()\n",
    "\n",
    "\n",
    "    epoch_train_loss = train_loss/len(train_loader)\n",
    "    # epoch_validation_loss = validation_loss/len(validation_loader) \n",
    "    epoch_train_acc1 = (train_correct1/train_total)*100\n",
    "    epoch_train_acc2 = (train_correct2/train_total)*100\n",
    "    epoch_train_acc3 = (train_correct3/train_total)*100\n",
    "    epoch_train_acc4 = (train_correct4/train_total)*100\n",
    "    epoch_train_acc5 = (train_correct5/train_total)*100\n",
    "    # epoch_validation_acc = (validation_correct1/validation_total)*100\n",
    "\n",
    "    print(\"Epoch [%d/%d]  Training Loss: %.5f  Acc1: %.5f  Acc2: %.5f  Acc3: %.5f  Acc4: %.5f  Acc5: %.5f \" %(epoch+1, num_epochs, epoch_train_loss, epoch_train_acc1, epoch_train_acc2, epoch_train_acc3, epoch_train_acc4, epoch_train_acc5))\n",
    "    print(f\"Epoch {epoch},  Loss : {epoch_train_loss},  Acc : {train_correct/train_total}\")\n",
    "    \n",
    "    # print(\"Epoch [%d/%d]  Training Loss: %.5f  Training Acc: %.5f  Validation Loss: %.5f   Validation Accuracy: %.5f \" %(epoch+1, N_EPOCHS, epoch_train_loss, epoch_train_acc, epoch_validation_loss, epoch_validation_acc))\n",
    "    trainlosslist.append(epoch_train_loss)\n",
    "    \n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# plot(trainlosslist, validationlosslist, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27a961f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182089ef4ad042259ee1d1ba1936919f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-071ce5a19ab5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0moutput_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0moutput_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for i, data in tqdm(enumerate(validation_loader)):\n",
    "    inputs = data[0].to(device)\n",
    "    labels = data[1]\n",
    "    \n",
    "    label = []\n",
    "    \n",
    "    for l in range(len(labels[0])):\n",
    "        label.append([])\n",
    "        length = labels[0][l]\n",
    "\n",
    "        for j in range(int(length)):\n",
    "            character = labels[1][l][j]\n",
    "            output_array = [0]*10\n",
    "            output_array[int(character)] = 1\n",
    "            label[l].append(output_array)\n",
    "\n",
    "        for j in range(int(length), 5):\n",
    "            output_array = [0]*10\n",
    "            output_array[10] = 1\n",
    "            label[l].append(output_array)\n",
    "\n",
    "    label = torch.Tensor(label).to(device)\n",
    "    outputs = model(inputs.to(device))\n",
    "\n",
    "    # # calculate loss\n",
    "    # loss_label = criterion(outputs['label'], label)\n",
    "\n",
    "    # # loss = loss #+ loss2 + loss3 + loss4 + loss5\n",
    "    # loss = loss_label\n",
    "\n",
    "    pred = torch.argmax(outputs['label'], 2)\n",
    "    \n",
    "    label = torch.argmax(label, axis=2)\n",
    "\n",
    "    train_correct += (torch.sum(label==pred, axis=1)==5).nonzero().shape[0]\n",
    "    \n",
    "    train_total += BATCH\n",
    "    \n",
    "    correct = torch.sum(label==pred, axis=0)\n",
    "    \n",
    "    train_correct1 += (correct[0])\n",
    "    train_correct2 += (correct[1])\n",
    "    train_correct3 += (correct[2])\n",
    "    train_correct4 += (correct[3])\n",
    "    train_correct5 += (correct[4])\n",
    "\n",
    "epoch_train_loss = train_loss/len(train_loader)\n",
    "# epoch_validation_loss = validation_loss/len(validation_loader) \n",
    "epoch_train_acc1 = (train_correct1/train_total)*100\n",
    "epoch_train_acc2 = (train_correct2/train_total)*100\n",
    "epoch_train_acc3 = (train_correct3/train_total)*100\n",
    "epoch_train_acc4 = (train_correct4/train_total)*100\n",
    "epoch_train_acc5 = (train_correct5/train_total)*100\n",
    "# epoch_validation_acc = (validation_correct1/validation_total)*100\n",
    "\n",
    "print(\"Epoch [%d/%d]  Validation Loss: %.5f  Acc1: %.5f  Acc2: %.5f  Acc3: %.5f  Acc4: %.5f  Acc5: %.5f \" %(epoch+1, num_epochs, epoch_train_loss, epoch_train_acc1, epoch_train_acc2, epoch_train_acc3, epoch_train_acc4, epoch_train_acc5))\n",
    "print(f\"Epoch {epoch},  Loss : {epoch_train_loss},  Acc : {train_correct/train_total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce27a437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
