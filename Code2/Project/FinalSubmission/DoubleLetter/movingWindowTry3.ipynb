{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97057e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D\n",
    "from keras import backend as k\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "981d0ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83b74777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPickleData(file):\n",
    "    data = pickle.load(open(file, 'rb'));\n",
    "    images = data[0];\n",
    "    labels = data[1];\n",
    "    return [images, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a207336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = applications.VGG19(weights = \"imagenet\", include_top=False,\\\n",
    "                           input_shape = (60, 40, 3))\n",
    "inputt = Input(shape =  (60,40,3), name = 'captcha_input')\n",
    "output_vgg16_conv = model(inputt)\n",
    "x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "predictions = Dense(10, activation=\"softmax\")(x)\n",
    "model_final = Model(inputt,predictions)\n",
    "model_final.compile(loss = \"categorical_crossentropy\",\\\n",
    "                    optimizer = tf.keras.optimizers.SGD(learning_rate=0.0001, momentum=0.9), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf0bce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./../SingleLetter/singleCharAccNewData1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc562335",
   "metadata": {},
   "outputs": [],
   "source": [
    "[images,labels] = loadPickleData(\"./../Data/pickledFiles/Num_NewData_2char_3channel.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ba68940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2de1d4a52f34f4daf4d6449a404b0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finalPreds = []\n",
    "preds = []\n",
    "for j in tqdm(range(2)):\n",
    "    img = images[:, :, 40*j:40*(j+1), :]\n",
    "    pred = np.argmax(model.predict(img), axis=1)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9715ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8a15bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "catTuple = (torch.from_numpy(preds[0]), torch.from_numpy(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57940a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfa60c76ad9476b8948f36c6c5523ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2len preds\n",
    "finalPreds = [int(catTuple[0][i])*10+int(catTuple[1][i]) for i in tqdm(range(len(preds[0])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "590920e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels), len(finalPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae72dda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, numpy.ndarray)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(finalPreds), type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbd9a8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4616"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(finalPreds == labels)/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68cef97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[images,labels] = loadPickleData(\"./../Data/pickledFiles/Num_NewData_3char_3channel.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fd51d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748a752f52c741b397c92c1e8f0671cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finalPreds = []\n",
    "preds = []\n",
    "for j in tqdm(range(3)):\n",
    "    img = images[:, :, 40*j:40*(j+1), :]\n",
    "    pred = np.argmax(model.predict(img), axis=1)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59510b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a526d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "catTuple = (torch.from_numpy(preds[0]), torch.from_numpy(preds[1]), torch.from_numpy(preds[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "083a9b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d0264b26b843968d90ac3196ee267e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3len preds\n",
    "finalPreds = [int(catTuple[0][i])*100+int(catTuple[1][i])*10+int(catTuple[2][i]) for i in tqdm(range(len(preds[0])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d363070c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2484"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(finalPreds == labels)/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db322eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "[images,labels] = loadPickleData(\"./../Data/pickledFiles/Num_NewData_4char_3channel.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe099bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775f9777abf64c0aa85d72bb0fae6034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finalPreds = []\n",
    "preds = []\n",
    "for j in tqdm(range(4)):\n",
    "    img = images[:, :, 40*j:40*(j+1), :]\n",
    "    pred = np.argmax(model.predict(img), axis=1)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "400a7932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85ba88f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "catTuple = (torch.from_numpy(preds[0]), torch.from_numpy(preds[1]), torch.from_numpy(preds[2]), torch.from_numpy(preds[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54a7ef99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6237ea84e57f4f688fbea422c70aeefe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4len preds\n",
    "finalPreds = [int(catTuple[0][i])*1000+int(catTuple[1][i])*100+int(catTuple[2][i])*10+int(catTuple[3][i]) for i in tqdm(range(len(preds[0])))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d64a8260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1014"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(finalPreds == labels)/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ea7e1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "[images,labels] = loadPickleData(\"./../Data/pickledFiles/Num_NewData_5char_3channel.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d15e2811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c6625b3d124e51bd66044cc4c35a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finalPreds = []\n",
    "preds = []\n",
    "for j in tqdm(range(5)):\n",
    "    img = images[:, :, 40*j:40*(j+1), :]\n",
    "    pred = np.argmax(model.predict(img), axis=1)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da9dd1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49c03e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "catTuple = (torch.from_numpy(preds[0]), torch.from_numpy(preds[1]), torch.from_numpy(preds[2]), torch.from_numpy(preds[3]), torch.from_numpy(preds[4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2458f98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1bb157f57e43828aec6628bcf6835d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5len preds\n",
    "finalPreds = [int(catTuple[0][i])*10000+int(catTuple[1][i])*1000+int(catTuple[2][i])*100+int(catTuple[3][i])*10+int(catTuple[4][i]) for i in tqdm(range(len(preds[0])))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1350436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(finalPreds == labels)/len(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
