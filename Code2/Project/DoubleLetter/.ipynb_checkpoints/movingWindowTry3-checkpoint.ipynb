{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607a19f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D\n",
    "from keras import backend as k\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babe6143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e2fe9951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPickleData(file):\n",
    "    data = pickle.load(open(file, 'rb'));\n",
    "    images = data[0];\n",
    "    labels = data[1];\n",
    "    return [images, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df26a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = applications.VGG19(weights = \"imagenet\", include_top=False,\\\n",
    "                           input_shape = (60, 40, 3))\n",
    "inputt = Input(shape =  (60,40,3), name = 'captcha_input')\n",
    "output_vgg16_conv = model(inputt)\n",
    "x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "predictions = Dense(10, activation=\"softmax\")(x)\n",
    "model_final = Model(inputt,predictions)\n",
    "model_final.compile(loss = \"categorical_crossentropy\",\\\n",
    "                    optimizer = tf.keras.optimizers.SGD(learning_rate=0.0001, momentum=0.9), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3064ef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./../SingleLetter/singleCharAccNewData1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6119a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "[images,labels] = loadPickleData(\"./../Data/pickledFiles/Num_NewData_2char_3channel.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "71696468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff24fd970924497b8f6f1c824e981bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finalPreds = []\n",
    "preds = []\n",
    "for j in tqdm(range(2)):\n",
    "    img = images[:, :, 40*j:40*(j+1), :]\n",
    "    pred = np.argmax(model.predict(img), axis=1)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "17db06cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9c3f2696",
   "metadata": {},
   "outputs": [],
   "source": [
    "catTuple = (torch.from_numpy(preds[0]), torch.from_numpy(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6dd242b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714c430335c84852b5462dc336270a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2len preds\n",
    "finalPreds = [int(catTuple[0][i])*10+int(catTuple[1][i]) for i in tqdm(range(len(preds[0])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "885d10c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels), len(finalPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0870355f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, numpy.ndarray)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(finalPreds), type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3ac74330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4258"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(finalPreds == labels)/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "81afce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "[images,labels] = loadPickleData(\"./../Data/pickledFiles/Num_NewData_3char_3channel.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f058d3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c04d55f991444d93b3aac91e499396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finalPreds = []\n",
    "preds = []\n",
    "for j in tqdm(range(3)):\n",
    "    img = images[:, :, 40*j:40*(j+1), :]\n",
    "    pred = np.argmax(model.predict(img), axis=1)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "24aa9569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "931f9cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "catTuple = (torch.from_numpy(preds[0]), torch.from_numpy(preds[1]), torch.from_numpy(preds[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d7e7b399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb06e5fe3caa45bc9d2e97e6f19d98bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3len preds\n",
    "finalPreds = [int(catTuple[0][i])*100+int(catTuple[1][i])*10+int(catTuple[2][i]) for i in tqdm(range(len(preds[0])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9453f4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2138"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(finalPreds == labels)/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6ec9c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "[images,labels] = loadPickleData(\"./../Data/pickledFiles/Num_NewData_4char_3channel.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "11e74da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c89e262db0c4b979930f4eb85b05f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finalPreds = []\n",
    "preds = []\n",
    "for j in tqdm(range(4)):\n",
    "    img = images[:, :, 40*j:40*(j+1), :]\n",
    "    pred = np.argmax(model.predict(img), axis=1)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "60e5b3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3006fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "catTuple = (torch.from_numpy(preds[0]), torch.from_numpy(preds[1]), torch.from_numpy(preds[2]), torch.from_numpy(preds[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3d673a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5754a9d0338e420b9c1c04a438b11d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4len preds\n",
    "finalPreds = [int(catTuple[0][i])*1000+int(catTuple[1][i])*100+int(catTuple[2][i])*10+int(catTuple[3][i]) for i in tqdm(range(len(preds[0])))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cdbe8748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.079"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(finalPreds == labels)/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8fb6ac5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "[images,labels] = loadPickleData(\"./../Data/pickledFiles/Num_NewData_5char_3channel.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0b4d36cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0379fe7553c4775bc3ac6026d718959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finalPreds = []\n",
    "preds = []\n",
    "for j in tqdm(range(5)):\n",
    "    img = images[:, :, 40*j:40*(j+1), :]\n",
    "    pred = np.argmax(model.predict(img), axis=1)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "27763882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cc953b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "catTuple = (torch.from_numpy(preds[0]), torch.from_numpy(preds[1]), torch.from_numpy(preds[2]), torch.from_numpy(preds[3]), torch.from_numpy(preds[4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "47958eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69d7000289d40f2accfee08770f6ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5len preds\n",
    "finalPreds = [int(catTuple[0][i])*10000+int(catTuple[1][i])*1000+int(catTuple[2][i])*100+int(catTuple[3][i])*10+int(catTuple[4][i]) for i in tqdm(range(len(preds[0])))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1f5c226c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0224"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(finalPreds == labels)/len(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
